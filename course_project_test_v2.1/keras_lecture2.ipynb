{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXE483S2NeSb",
        "outputId": "5f8712a3-e430-43bf-b689-f123f8f70ac3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape (Reshape)           (None, 64, 64, 16)        0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 60, 60, 32)        12832     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 30, 30, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 30, 30, 1)         33        \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 900)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                14416     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 27,281\n",
            "Trainable params: 27,281\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Define the model using functional API:\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Conv2D,MaxPool2D,Input,Reshape,Flatten\n",
        "import keras\n",
        "import numpy as np\n",
        "\n",
        "layers = [Input(shape=(256,256,1)),\n",
        "      Reshape((64,64,-1)),\n",
        "      Conv2D(filters=32,kernel_size=5),\n",
        "      MaxPool2D(2),\n",
        "      Conv2D(filters=1,kernel_size=1),\n",
        "      Flatten(),\n",
        "      Dense(16,activation='sigmoid')]\n",
        "model = Sequential(layers)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZWO8mtWQi_B",
        "outputId": "6f55bef3-3102-4482-8869-56db6e6ab0ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)           [(None, 256, 256, 1  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " reshape_2 (Reshape)            (None, 64, 64, 16)   0           ['input_6[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 240, 240, 8)  2320        ['input_6[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 60, 60, 8)    3208        ['reshape_2[0][0]']              \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 60, 60, 8)   0           ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 60, 60, 16)   0           ['conv2d_4[0][0]',               \n",
            "                                                                  'max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 5,528\n",
            "Trainable params: 5,528\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Define the model using functional API:\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense,Conv2D,MaxPool2D,Input,Reshape,Flatten,concatenate\n",
        "import keras\n",
        "import numpy as np\n",
        "\n",
        "def my_model():\n",
        "  # define layers\n",
        "  input_tensor = Input(shape=(256,256,1))\n",
        "  reshape_layer = Reshape((64,64,-1))\n",
        "  conv2d_1 = Conv2D(filters=8,kernel_size=5)\n",
        "  conv2d_2 = Conv2D(filters=8,kernel_size=17)\n",
        "  max_pool_layer = MaxPool2D(4)\n",
        "\n",
        "  input_tensor_reshape = reshape_layer(input_tensor)\n",
        "  conv1_out = conv2d_1(input_tensor_reshape)\n",
        "  conv2_out = conv2d_2(input_tensor)\n",
        "  max_pool_out = max_pool_layer(conv2_out)\n",
        "  cat_out = concatenate([conv1_out,max_pool_out],axis=-1)\n",
        "  model = Model(inputs=input_tensor, outputs=cat_out)\n",
        "  return model\n",
        "\n",
        "my_model = my_model()\n",
        "my_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vloUHp9uS70p",
        "outputId": "5cb1c5c3-898d-4384-83ee-26418bca3ced"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "422/422 [==============================] - 11s 24ms/step - loss: 0.2306 - accuracy: 0.9338 - val_loss: 0.1103 - val_accuracy: 0.9660\n",
            "Epoch 2/8\n",
            "422/422 [==============================] - 8s 18ms/step - loss: 0.0842 - accuracy: 0.9738 - val_loss: 0.0790 - val_accuracy: 0.9742\n",
            "Epoch 3/8\n",
            "422/422 [==============================] - 8s 18ms/step - loss: 0.0528 - accuracy: 0.9833 - val_loss: 0.0613 - val_accuracy: 0.9800\n",
            "Epoch 4/8\n",
            "422/422 [==============================] - 8s 18ms/step - loss: 0.0363 - accuracy: 0.9884 - val_loss: 0.0762 - val_accuracy: 0.9790\n",
            "Epoch 5/8\n",
            "422/422 [==============================] - 8s 18ms/step - loss: 0.0285 - accuracy: 0.9911 - val_loss: 0.0799 - val_accuracy: 0.9783\n",
            "Epoch 6/8\n",
            "422/422 [==============================] - 8s 18ms/step - loss: 0.0213 - accuracy: 0.9929 - val_loss: 0.0757 - val_accuracy: 0.9797\n",
            "Epoch 7/8\n",
            "422/422 [==============================] - 8s 18ms/step - loss: 0.0177 - accuracy: 0.9944 - val_loss: 0.0770 - val_accuracy: 0.9815\n",
            "Epoch 8/8\n",
            "422/422 [==============================] - 8s 19ms/step - loss: 0.0161 - accuracy: 0.9946 - val_loss: 0.0931 - val_accuracy: 0.9777\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f012f18cfd0>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Input\n",
        "from keras.losses import SparseCategoricalCrossentropy\n",
        "\n",
        "df_orig_train = pd.read_csv('/content/drive/MyDrive/keras/mnist_train.csv',header=None)\n",
        "df_orig_test = pd.read_csv('/content/drive/MyDrive/keras/mnist_test.csv',header=None)\n",
        "df_train_values = df_orig_train.values\n",
        "df_test_values = df_orig_test.values\n",
        "train_feat_ori,train_label_ori = df_train_values[:,1:]/255.0,df_train_values[:,0]\n",
        "test_feat,test_label = df_test_values[:,1:]/255.0,df_test_values[:,0]\n",
        "train_feat,val_feat = train_feat_ori[6000:],train_feat_ori[:6000]\n",
        "train_label,val_label = train_label_ori[6000:],train_label_ori[:6000]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(784,)))\n",
        "model.add(Dense(512, activation='relu')) \n",
        "model.add(Dense(512, activation='relu')) \n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.compile(optimizer='adam',loss= 'sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 8\n",
        "model.fit(train_feat, train_label, batch_size=batch_size, epochs=epochs, validation_data = (val_feat,val_label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7m7gXoO7VtdW",
        "outputId": "ce1be78b-d0cb-416e-d4af-362e0b0b87d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0/15]\n",
            "420/420 [==============================] - 28s 65ms/step - loss: 1.2024 - accuracy: 0.6071 - val_loss: 0.3391 - val_accuracy: 0.8444\n",
            "[1/15]\n",
            "420/420 [==============================] - 27s 65ms/step - loss: 0.7259 - accuracy: 0.7738 - val_loss: 0.3641 - val_accuracy: 0.9111\n",
            "[2/15]\n",
            "420/420 [==============================] - 27s 65ms/step - loss: 0.5904 - accuracy: 0.8238 - val_loss: 0.3575 - val_accuracy: 0.8444\n",
            "[3/15]\n",
            "420/420 [==============================] - 27s 65ms/step - loss: 0.5424 - accuracy: 0.8452 - val_loss: 0.1123 - val_accuracy: 1.0000\n",
            "[4/15]\n",
            "420/420 [==============================] - 30s 71ms/step - loss: 0.5796 - accuracy: 0.8429 - val_loss: 0.1937 - val_accuracy: 0.9556\n",
            "[5/15]\n",
            "420/420 [==============================] - 27s 64ms/step - loss: 0.4774 - accuracy: 0.8643 - val_loss: 0.1610 - val_accuracy: 0.9333\n",
            "[6/15]\n",
            "420/420 [==============================] - 30s 71ms/step - loss: 0.3871 - accuracy: 0.8881 - val_loss: 0.2727 - val_accuracy: 0.9333\n",
            "[7/15]\n",
            "420/420 [==============================] - 27s 63ms/step - loss: 0.4955 - accuracy: 0.8738 - val_loss: 0.2080 - val_accuracy: 0.9333\n",
            "[8/15]\n",
            "420/420 [==============================] - 27s 64ms/step - loss: 0.3837 - accuracy: 0.8786 - val_loss: 0.0780 - val_accuracy: 0.9778\n",
            "[9/15]\n",
            "420/420 [==============================] - 28s 66ms/step - loss: 0.2919 - accuracy: 0.9048 - val_loss: 0.1097 - val_accuracy: 0.9778\n",
            "[10/15]\n",
            "420/420 [==============================] - 34s 81ms/step - loss: 0.3388 - accuracy: 0.9024 - val_loss: 0.1818 - val_accuracy: 0.9333\n",
            "[11/15]\n",
            "420/420 [==============================] - 37s 89ms/step - loss: 0.3710 - accuracy: 0.8833 - val_loss: 0.3433 - val_accuracy: 0.8889\n",
            "[12/15]\n",
            "420/420 [==============================] - 32s 77ms/step - loss: 0.3556 - accuracy: 0.8929 - val_loss: 0.0462 - val_accuracy: 0.9778\n",
            "[13/15]\n",
            "420/420 [==============================] - 30s 71ms/step - loss: 0.3772 - accuracy: 0.8881 - val_loss: 0.0375 - val_accuracy: 1.0000\n",
            "[14/15]\n",
            "420/420 [==============================] - 28s 68ms/step - loss: 0.3477 - accuracy: 0.9048 - val_loss: 0.3094 - val_accuracy: 0.9111\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Input\n",
        "from keras.losses import SparseCategoricalCrossentropy\n",
        "\n",
        "import numpy as np\n",
        "import linecache\n",
        "import random\n",
        "class DataGenerator(keras.utils.Sequence):\n",
        "  'Generates data for Keras'\n",
        "  def __init__(self, csv_path, indexes, bs):\n",
        "    # initilizes some variables \n",
        "    self.csv_path = csv_path\n",
        "    self.norm_facor = 255.0\n",
        "    self.indexes = indexes\n",
        "    self.bs = bs\n",
        "    random.shuffle(self.indexes)\n",
        "  def __len__(self):\n",
        "    # return the total number of samples in the dataset\n",
        "    return (len(self.indexes))//self.bs-1\n",
        "  def __getitem__(self,index):\n",
        "    # get one sample according to the index\n",
        "    feat_all = []\n",
        "    label_all = []\n",
        "    for this_index in range(index*self.bs,(index+1)*self.bs):\n",
        "      line_index = self.indexes[index]\n",
        "      line_str = linecache.getline(self.csv_path,line_index)\n",
        "      line_val = [int(i) for i in line_str.split(',') if len(i)]\n",
        "      label = line_val[0]\n",
        "      feat = np.array(line_val[1:])/self.norm_facor\n",
        "      feat_all.append(feat)\n",
        "      label_all.append(label)\n",
        "\n",
        "    return np.array(feat_all),np.array(label_all)\n",
        "  def shuffle(self):\n",
        "    random.shuffle(self.indexes)\n",
        "\n",
        "\n",
        "indexes = [i for i in range(60000)]\n",
        "train_index = indexes[6000:]\n",
        "val_index = indexes[:6000]\n",
        "batch_size = 128\n",
        "train_set = DataGenerator('/content/drive/MyDrive/keras/mnist_train.csv',train_index,batch_size)\n",
        "val_set = DataGenerator('/content/drive/MyDrive/keras/mnist_train.csv',val_index,batch_size)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(784,)))\n",
        "model.add(Dense(512, activation='relu')) \n",
        "model.add(Dense(512, activation='relu')) \n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.compile(optimizer='adam',loss= 'sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "epochs = 15\n",
        "for i_epoch in range(epochs):\n",
        "  print('[{}/{}]'.format(i_epoch,epochs))\n",
        "  model.fit(train_set, steps_per_epoch = len(train_set), epochs=1, validation_data = val_set,validation_steps=len(val_set))\n",
        "  train_set.shuffle()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1nquKKIqRMO",
        "outputId": "e9b10f73-a29a-47ab-ac3f-6a97d54f1c6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0/50],val_acc:0.8888888955116272\n",
            "[1/50],val_acc:0.9333333373069763\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Input\n",
        "\n",
        "import numpy as np\n",
        "import linecache\n",
        "import random\n",
        "import tensorflow as tf\n",
        "\n",
        "class DataGenerator(keras.utils.Sequence):\n",
        "  'Generates data for Keras'\n",
        "  def __init__(self, csv_path, indexes, bs):\n",
        "    # initilizes some variables \n",
        "    self.csv_path = csv_path\n",
        "    self.norm_facor = 255.0\n",
        "    self.indexes = indexes\n",
        "    self.bs = bs\n",
        "    random.shuffle(self.indexes)\n",
        "  def __len__(self):\n",
        "    # return the total number of samples in the dataset\n",
        "    return (len(self.indexes))//self.bs-1\n",
        "  def __getitem__(self,index):\n",
        "    # get one sample according to the index\n",
        "    feat_all = []\n",
        "    label_all = []\n",
        "    for this_index in range(index*self.bs,(index+1)*self.bs):\n",
        "      line_index = self.indexes[index]\n",
        "      line_str = linecache.getline(self.csv_path,line_index)\n",
        "      line_val = [int(i) for i in line_str.split(',') if len(i)]\n",
        "      label = line_val[0]\n",
        "      feat = np.array(line_val[1:])/self.norm_facor\n",
        "      feat_all.append(feat)\n",
        "      label_all.append(label)\n",
        "\n",
        "    return np.array(feat_all),np.array(label_all)\n",
        "  def shuffle(self):\n",
        "    random.shuffle(self.indexes)\n",
        "\n",
        "\n",
        "indexes = [i for i in range(60000)]\n",
        "train_index = indexes[6000:]\n",
        "val_index = indexes[:6000]\n",
        "batch_size = 128\n",
        "train_set = DataGenerator('/content/drive/MyDrive/keras/mnist_train.csv',train_index,batch_size)\n",
        "val_set = DataGenerator('/content/drive/MyDrive/keras/mnist_train.csv',val_index,batch_size)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(784,)))\n",
        "model.add(Dense(512, activation='relu')) \n",
        "model.add(Dense(512, activation='relu')) \n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.compile(optimizer='adam',loss= 'sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
        "optimizer = keras.optimizers.Adam()\n",
        "val_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
        "epochs = 50\n",
        "best_metric = 100\n",
        "for epoch in range(epochs):\n",
        "  train_set.shuffle()\n",
        "  for step, (x_batch_train, y_batch_train) in enumerate(train_set):\n",
        "        with tf.GradientTape() as tape:\n",
        "            logits = model(x_batch_train, training=True)\n",
        "            loss_value = loss_fn(y_batch_train, logits)\n",
        "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "  for x_batch_val, y_batch_val in val_set:\n",
        "    val_logits = model(x_batch_val, training=False)\n",
        "    val_acc_metric.update_state(y_batch_val, val_logits)\n",
        "  val_acc = val_acc_metric.result()\n",
        "  print(\"[{}/{}],val_acc:{}\".format(epoch,epochs,float(val_acc)))\n",
        "  if float(val_acc) < best_metric:\n",
        "    best_metric = float(val_acc)\n",
        "    model.save('path_to_location.h5')\n",
        "  val_acc_metric.reset_states()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_2yIr1ICW7Bx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1, 100, 128)\n",
            "(1, 100, 512)\n",
            "(1, 512)\n"
          ]
        }
      ],
      "source": [
        "from keras.layers import Dense,LSTM\n",
        "import keras\n",
        "import numpy as np\n",
        "\n",
        "x = keras.backend.constant(np.random.randn(1,100,128))\n",
        "lstm_layer1 = LSTM(512,return_sequences=True)\n",
        "lstm_layer2 = LSTM(512,return_sequences=False)\n",
        "y1 = lstm_layer1(x)\n",
        "y2 = lstm_layer2(x)\n",
        "for ii in [x,y1,y2]:\n",
        "  print(ii.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Input,Conv2D, MaxPool2D,Flatten,Reshape\n",
        "\n",
        "layer = [\n",
        "    Input(shape=(256,256,1)),\n",
        "    Reshape((64,64,-1)),\n",
        "    Conv2D(32,5),\n",
        "    MaxPool2D(2),\n",
        "    Conv2D(1,1),\n",
        "    Flatten(),\n",
        "    Dense(16,activation ='sigmoid')\n",
        "]\n",
        "model = Sequential(layer)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape_2 (Reshape)         (None, 64, 64, 16)        0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 60, 60, 32)        12832     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 30, 30, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 30, 30, 1)         33        \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 900)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 16)                14416     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 27,281\n",
            "Trainable params: 27,281\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.layers import Dense, Input,Conv2D, MaxPool2D,Flatten,Reshape,concatenate\n",
        "from keras.models import Model\n",
        "def new_modle():\n",
        "    input_tensor = Input(shape=(256,256,1))\n",
        "    reshape_layer = Reshape((64,64,-1))\n",
        "    conv1 = Conv2D(8,5)\n",
        "    conv2 = Conv2D(8,17)\n",
        "    mxp = MaxPool2D(4)\n",
        "\n",
        "    #\n",
        "    reshaped = reshape_layer(input_tensor)\n",
        "    concl_out = conv1(reshaped)\n",
        "    conv2_out = conv2(input_tensor)\n",
        "    mxp_out = mxp(conv2_out)\n",
        "    out = concatenate([concl_out,mxp_out],axis= -1)\n",
        "\n",
        "    model = Model( inputs = input_tensor,outputs = out)\n",
        "    model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_12 (InputLayer)          [(None, 256, 256, 1  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " reshape_11 (Reshape)           (None, 64, 64, 16)   0           ['input_12[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 240, 240, 8)  2320        ['input_12[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 60, 60, 8)    3208        ['reshape_11[0][0]']             \n",
            "                                                                                                  \n",
            " max_pooling2d_11 (MaxPooling2D  (None, 60, 60, 8)   0           ['conv2d_23[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate)    (None, 60, 60, 16)   0           ['conv2d_22[0][0]',              \n",
            "                                                                  'max_pooling2d_11[0][0]']       \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 5,528\n",
            "Trainable params: 5,528\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "new_modle()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
