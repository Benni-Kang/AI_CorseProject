{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import folium\n",
    "import math \n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "path = os.getcwd()\n",
    "df1 = pd.read_csv(\"CaliforniaRoadNetwork_Edges.csv\")\n",
    "df2 = pd.read_csv(\"CaliforniaRoadNetwork_Nodes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Draw_map():\n",
    "    m = folium.Map(\n",
    "        location=[41.974556, -121.904167],\n",
    "        zoom_start=7.5\n",
    "        \n",
    "    )\n",
    "    for i in range(len(df2)):\n",
    "            m.add_child(\n",
    "            folium.CircleMarker(\n",
    "                [df2[\"Latitude\"][i],df2[\"Longitude\"][i]],\n",
    "                radius=2, # define how big you want the circle markers to be\n",
    "                color='yellow',\n",
    "                fill=True,\n",
    "                fill_color='red',\n",
    "                fill_opacity=1.5\n",
    "        )\n",
    "        )\n",
    "    m.add_child(folium.LatLngPopup())\n",
    "    m.save('Position Visualization.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_EuclideanDistance(node1,node2): \n",
    "    node1_Longitude = float(df2.loc[df2[\"NodeID\"]==node1, :][\"Longitude\"])\n",
    "    node1_Latitude = float(df2.loc[df2[\"NodeID\"]==node1, :][\"Latitude\"])\n",
    "   \n",
    "    node2_Longitude = float(df2.loc[df2[\"NodeID\"]==node2, :][\"Longitude\"])\n",
    "    node2_Latitude = float(df2.loc[df2[\"NodeID\"]==node2, :][\"Latitude\"])\n",
    "\n",
    "    return math.sqrt(pow(node1_Longitude-node2_Longitude,2) + pow(node1_Latitude-node2_Latitude,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Dict():\n",
    "    graph_search = {}\n",
    "    ##进入循环\n",
    "    for i in range(len(df2)):\n",
    "        next_node = []\n",
    "        this_node = int(df2.loc[i,[\"NodeID\"]])\n",
    "        endnode = df1.loc[df1[\"StartNodeID\"]==this_node, :][\"EndNodeID\"]\n",
    "        for e in endnode:\n",
    "            #groupby 找到所有的node 然后遍历每个node\n",
    "            if e not in next_node:\n",
    "                child_node = (e,get_EuclideanDistance(this_node,e))\n",
    "                next_node.append(child_node)\n",
    "        graph_search[this_node] = next_node\n",
    "    return graph_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_search = get_Dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bfs(graph_to_search, initial_state, goal_state, verbose=False):\n",
    "    # this is a list of a list because we need to eventually return\n",
    "    # the entire PATH from the initial state to the goal state. So,\n",
    "    # each element in this list represents a path from the the initial\n",
    "    # state to one frontier node. We use the first element in each path\n",
    "    # to represent the cost.\n",
    "    frontiers = [[0, initial_state]]  # the frontier list only has the initial state, with a cost of 0.\n",
    "    visited = []\n",
    "\n",
    "    while len(frontiers) > 0:   # use while loop to iteratively perform search\n",
    "        # if verbose:  # print out detailed information in each iteration\n",
    "        #     print('Frontiers (paths):')\n",
    "        #     for x in frontiers:\n",
    "        #         print('  -', x)\n",
    "        #     print('Visited:', visited)\n",
    "        #     print('\\n')\n",
    "        \n",
    "        path = frontiers.pop(0)  # Get the first element in the list\n",
    "        node = path[-1]  # Get the last node in this path\n",
    "        \n",
    "        if node in visited:  # check if we have expanded this node, if yes then skip this\n",
    "            continue\n",
    "            \n",
    "        actions = graph_to_search[node] # get the possible actions\n",
    "        for next_node, next_cost in actions:\n",
    "            new_path = path.copy()\n",
    "            new_path.append(next_node)\n",
    "            new_path[0] = new_path[0] + next_cost\n",
    "            \n",
    "            if next_node in visited or new_path in frontiers:\n",
    "                continue  # skip this node if it is already in the frontiers or the visited list.\n",
    "            \n",
    "            # check if we reached the goal state or not\n",
    "            if next_node == goal_state:\n",
    "                goal_path = new_path[1:]\n",
    "                goal_cost = new_path[0]\n",
    "                return goal_path, goal_cost  # if yes, we can return this path and its cost\n",
    "            else:\n",
    "                frontiers.append(new_path)  # add to the frontiers\n",
    "        \n",
    "        # after exploring all actions, we add this node to the visited list\n",
    "        visited.append(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "bfs(graph_search,10,200,verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12402 1763\n",
      "None\n",
      "Run_time: 0.0013876000002710498\n"
     ]
    }
   ],
   "source": [
    "time_start = time.perf_counter()\n",
    "start_node = np.random.randint(0,len(df2))\n",
    "end_node = np.random.randint(0,len(df2))\n",
    "print(start_node,end_node)\n",
    "print(bfs(graph_search,start_node,end_node,verbose = False))\n",
    "time_end = time.perf_counter()\n",
    "run_time = time_end - time_start\n",
    "print('Run_time:',run_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11806 16988\n"
     ]
    }
   ],
   "source": [
    "start_node = np.random.randint(0,len(df2))\n",
    "end_node = np.random.randint(0,len(df2))\n",
    "print(start_node,end_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfs(graph_to_search, initial_state, goal_state, verbose=False):\n",
    "    # this is a list of a list because we need to eventually return\n",
    "    # the entire PATH from the initial state to the goal state. So,\n",
    "    # each element in this list represents a path from the the initial\n",
    "    # state to one frontier node. We use the first element in each path\n",
    "    # to represent the cost.\n",
    "    frontiers = [[0, initial_state]]  # the frontier list only has the initial state, with a cost of 0.\n",
    "    visited = []\n",
    "\n",
    "    while len(frontiers) > 0:   # use while loop to iteratively perform search\n",
    "        if verbose:  # print out detailed information in each iteration\n",
    "            print('Frontiers (paths):')\n",
    "            for x in frontiers:\n",
    "                print('  -', x)\n",
    "            print('Visited:', visited)\n",
    "            print('\\n')\n",
    "        \n",
    "        path = frontiers.pop(-1)  # Get the last element in the list\n",
    "        node = path[-1]  # Get the last node in this path\n",
    "        \n",
    "        if node in visited:  # check if we have expanded this node, if yes then skip this\n",
    "            continue\n",
    "            \n",
    "        actions = graph_to_search[node] # get the possible actions\n",
    "        for next_node, next_cost in actions:\n",
    "            new_path = path.copy()\n",
    "            new_path.append(next_node)\n",
    "            new_path[0] = new_path[0] + next_cost\n",
    "            \n",
    "            if next_node in visited or new_path in frontiers:\n",
    "                continue  # skip this node if it is already in the frontiers or the visited list.\n",
    "            \n",
    "            # check if we reached the goal state or not\n",
    "            if next_node == goal_state:\n",
    "                goal_path = new_path[1:]\n",
    "                goal_cost = new_path[0]\n",
    "                return goal_path, goal_cost  # if yes, we can return this path and its cost\n",
    "            else:\n",
    "                frontiers.append(new_path)  # add to the frontiers\n",
    "        \n",
    "        # after exploring all actions, we add this node to the visited list\n",
    "        visited.append(node)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uniform-cost Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_cost_search(graph_to_search, initial_state, goal_state, verbose=False):\n",
    "    # this is a list of a list because we need to eventually return\n",
    "    # the entire PATH from the initial state to the goal state. So,\n",
    "    # each element in this list represents a path from the the initial\n",
    "    # state to one frontier node. We use the first element in each path\n",
    "    # to represent the cost.\n",
    "    frontiers = [[0, initial_state]]  # the frontier list only has the initial state, with a cost of 0.\n",
    "    visited = []\n",
    "\n",
    "    while len(frontiers) > 0:   # use while loop to iteratively perform search\n",
    "        if verbose:  # print out detailed information in each iteration\n",
    "            print('Frontiers (paths):')\n",
    "            for x in frontiers:\n",
    "                print('  -', x)\n",
    "            print('Visited:', visited)\n",
    "            print('\\n')\n",
    "        \n",
    "        frontiers = sorted(frontiers, key=lambda x: x[0])\n",
    "        path = frontiers.pop(0)  # Get the first path in the queue\n",
    "        node = path[-1]  # Get the last node in this path\n",
    "        \n",
    "        if node == goal_state:\n",
    "            goal_path = path[1:]\n",
    "            goal_cost = path[0]\n",
    "            return goal_path, goal_cost\n",
    "        \n",
    "        if node in visited:  # check if we have expanded this node, if yes then skip this\n",
    "            continue\n",
    "            \n",
    "        actions = graph_to_search[node] # get the possible actions\n",
    "        for next_node, next_cost in actions:\n",
    "            new_path = path.copy()\n",
    "            new_path.append(next_node)\n",
    "            new_path[0] = new_path[0] + next_cost\n",
    "            \n",
    "            if next_node in visited or new_path in frontiers:\n",
    "                continue  # skip this node if it is already in the frontiers or the visited list.\n",
    "            \n",
    "            frontiers.append(new_path)  # add to the frontiers\n",
    "        \n",
    "        # after exploring all actions, we add this node to the visited list\n",
    "        visited.append(node)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_bfs with 1000 combinations of start and end nodes\n",
    "k = 1000\n",
    "s = sample(list(df1.StartNodeID),k) # start point\n",
    "e = sample(list(df1.EndNodeID),k)  #end point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range k:\n",
    "    bfs_result = bfs(graph_search, s[i], e[i], verbose=True)\n",
    "    print(bfs_result)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range k:\n",
    "    dfs_result = bfs(graph_search, s[i], e[i], verbose=True)\n",
    "    print(dfs_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range k:\n",
    "    uniform_result = bfs(graph_search, s[i], e[i], verbose=True)\n",
    "    print(uniform_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
