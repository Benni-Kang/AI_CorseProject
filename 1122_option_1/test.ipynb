{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import folium\n",
    "import math \n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"CaliforniaRoadNetwork_Edges.csv\")\n",
    "df2 = pd.read_csv(\"CaliforniaRoadNetwork_Nodes.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import folium\n",
    "# m = folium.Map(\n",
    "#     location=[41.974556, -121.904167],\n",
    "#     zoom_start=7.5\n",
    "    \n",
    "# )\n",
    "# for i in range(len(df2)):\n",
    "#         m.add_child(\n",
    "#         folium.CircleMarker(\n",
    "#               [df2[\"Latitude\"][i],df2[\"Longitude\"][i]],\n",
    "#              radius=2, # define how big you want the circle markers to be\n",
    "#             color='yellow',\n",
    "#             fill=True,\n",
    "#             fill_color='red',\n",
    "#              fill_opacity=1.5\n",
    "#      )\n",
    "#     )\n",
    "# m.add_child(folium.LatLngPopup())\n",
    "# display(m)\n",
    "# m.save('Position Visualization.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_EuclideanDistance(node1,node2): \n",
    "    node1_Longitude = float(df2.loc[df2[\"NodeID\"]==node1, :][\"Longitude\"])\n",
    "    node1_Latitude = float(df2.loc[df2[\"NodeID\"]==node1, :][\"Latitude\"])\n",
    "   \n",
    "    node2_Longitude = float(df2.loc[df2[\"NodeID\"]==node2, :][\"Longitude\"])\n",
    "    node2_Latitude = float(df2.loc[df2[\"NodeID\"]==node2, :][\"Latitude\"])\n",
    "\n",
    "    return math.sqrt(pow(node1_Longitude-node2_Longitude,2) + pow(node1_Latitude-node2_Latitude,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Dict():\n",
    "    graph_search = {}\n",
    "    ##进入循环\n",
    "    #单向算一次\n",
    "    for i in range(len(df2)):\n",
    "        next_node = []\n",
    "        this_node = int(df2.loc[i,[\"NodeID\"]])                             #遍历所有ID\n",
    "        endnode = df1.loc[df1[\"StartNodeID\"]==this_node, :][\"EndNodeID\"]   #找到这个id对应所有的终点ID\n",
    "        for e in endnode:\n",
    "            #groupby 找到所有的node 然后遍历每个node\n",
    "            # if e not in next_node:\n",
    "            child_node = (e,get_EuclideanDistance(this_node,e))\n",
    "            next_node.append(child_node)\n",
    "        graph_search[this_node] = next_node\n",
    "    \n",
    "    #反向算一次\n",
    "    for i in range(len(df2)):\n",
    "        this_node = int(df2.loc[i,[\"NodeID\"]])                             #遍历所有ID\n",
    "        start_node = df1.loc[df1[\"EndNodeID\"]==this_node, :][\"StartNodeID\"]   #找到这个id对应所有的终点ID\n",
    "        if len(start_node) != 0:\n",
    "            for e in start_node:\n",
    "                child_node = (e,get_EuclideanDistance(this_node,e))\n",
    "                graph_search[this_node].append(child_node)\n",
    "    return graph_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_search = get_Dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph_search_pd = pd.DataFrame.from_dict(graph_search, orient='index')\n",
    "# graph_search_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sld_to_des(des_node):\n",
    "    graph_search_sld = {}\n",
    "    for i in range(len(df2)):\n",
    "        graph_search_sld[i] = get_EuclideanDistance(int(des_node),i)\n",
    "    return graph_search_sld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sld_to_des(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bfs(graph_to_search, initial_state, goal_state, verbose=False):\n",
    "    # this is a list of a list because we need to eventually return\n",
    "    # the entire PATH from the initial state to the goal state. So,\n",
    "    # each element in this list represents a path from the the initial\n",
    "    # state to one frontier node. We use the first element in each path\n",
    "    # to represent the cost.\n",
    "    frontiers = [[0, initial_state]]  # the frontier list only has the initial state, with a cost of 0.\n",
    "    visited = []\n",
    "\n",
    "    while len(frontiers) > 0:   # use while loop to iteratively perform search\n",
    "        if verbose:  # print out detailed information in each iteration\n",
    "            print('Frontiers (paths):')\n",
    "            for x in frontiers:\n",
    "                print('  -', x)\n",
    "            print('Visited:', visited)\n",
    "            print('\\n')\n",
    "        \n",
    "        path = frontiers.pop(0)  # Get the first element in the list\n",
    "        node = path[-1]  # Get the last node in this path\n",
    "        \n",
    "        if node in visited:  # check if we have expanded this node, if yes then skip this\n",
    "            continue\n",
    "            \n",
    "        actions = graph_to_search[node] # get the possible actions\n",
    "        for next_node, next_cost in actions:\n",
    "            new_path = path.copy()\n",
    "            new_path.append(next_node)\n",
    "            new_path[0] = new_path[0] + next_cost\n",
    "            \n",
    "            if next_node in visited or new_path in frontiers:\n",
    "                continue  # skip this node if it is already in the frontiers or the visited list.\n",
    "            \n",
    "            # check if we reached the goal state or not\n",
    "            if next_node == goal_state:\n",
    "                goal_path = new_path[1:]\n",
    "                goal_cost = new_path[0]\n",
    "                return goal_path, goal_cost  # if yes, we can return this path and its cost\n",
    "            else:\n",
    "                frontiers.append(new_path)  # add to the frontiers\n",
    "        \n",
    "        # after exploring all actions, we add this node to the visited list\n",
    "        visited.append(node)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(graph_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1\n",
    "![avator](./200_Question/question1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bfs(graph_search, 0, 1894, verbose=False))\n",
    "print(bfs(graph_search, 4, 3115, verbose=False))\n",
    "print(bfs(graph_search, 18, 9186, verbose=False))\n",
    "print(bfs(graph_search, 25, 15061, verbose=False))\n",
    "print(bfs(graph_search, 33, 21040, verbose=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bfs(graph_search, 0, 1, verbose=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2\n",
    "![avator](./200_Question/question2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 BFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 DFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 UniformSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 GreedySearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_search(graph_to_search, initial_state, goal_state, heuristics_function, verbose=False):\n",
    "    # this is a list of a list because we need to eventually return\n",
    "    # the entire PATH from the initial state to the goal state. So,\n",
    "    # each element in this list represents a path from the the initial\n",
    "    # state to one frontier node. We use the first element in each path\n",
    "    # to represent the cost.\n",
    "    frontiers = [[0, initial_state]]  # the frontier list only has the initial state, with a cost of 0.\n",
    "    visited = []\n",
    "\n",
    "    while len(frontiers) > 0:   # use while loop to iteratively perform search\n",
    "        if verbose:  # print out detailed information in each iteration\n",
    "            print('Frontiers (paths):')\n",
    "            for x in frontiers:\n",
    "                print('  -', x)\n",
    "            print('Visited:', visited)\n",
    "            print('\\n')\n",
    "            \n",
    "        # get the nodes in frontiers to be expanded\n",
    "        frontier_heuristics = []\n",
    "        for x in frontiers:\n",
    "            frontier_heuristics.append(heuristics_function[x[-1]])\n",
    "        idx_to_pop = frontier_heuristics.index(min(frontier_heuristics))\n",
    "        \n",
    "        path = frontiers.pop(idx_to_pop)\n",
    "        node = path[-1]  # Get the last node in this path\n",
    "        \n",
    "        if node in visited:  # check if we have expanded this node, if yes then skip this\n",
    "            continue\n",
    "            \n",
    "        actions = graph_to_search[node] # get the possible actions\n",
    "        for next_node, next_cost in actions:\n",
    "            new_path = path.copy()\n",
    "            new_path.append(next_node)\n",
    "            new_path[0] = new_path[0] + next_cost\n",
    "            \n",
    "            if next_node in visited or new_path in frontiers:\n",
    "                continue  # skip this node if it is already in the frontiers or the visited list.\n",
    "            \n",
    "            # check if we reached the goal state or not\n",
    "            if next_node == goal_state:\n",
    "                goal_path = new_path[1:]\n",
    "                goal_cost = new_path[0]\n",
    "                return goal_path, goal_cost  # if yes, we can return this path and its cost\n",
    "            else:\n",
    "                frontiers.append(new_path)  # add to the frontiers\n",
    "        \n",
    "        # after exploring all actions, we add this node to the visited list\n",
    "        visited.append(node)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    initial_state = np.random.randint(0,21047)\n",
    "    goal_state = np.random.randint(0,21047)\n",
    "    print('The',i+1,'th combinations')\n",
    "    print(greedy_search(graph_search, initial_state, goal_state, heuristics_function=sld_to_des(goal_state), verbose=False))\n",
    "    print('----------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 A* Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a_star_search(graph_to_search, initial_state, goal_state, heuristics_function, verbose=False):\n",
    "    # this is a list of a list because we need to eventually return\n",
    "    # the entire PATH from the initial state to the goal state. So,\n",
    "    # each element in this list represents a path from the the initial\n",
    "    # state to one frontier node. We use the first element in each path\n",
    "    # to represent the cost.\n",
    "    frontiers = [[0, initial_state]]  # the frontier list only has the initial state, with a cost of 0.\n",
    "    visited = []\n",
    "\n",
    "    while len(frontiers) > 0:   # use while loop to iteratively perform search\n",
    "        if verbose:  # print out detailed information in each iteration\n",
    "            print('Frontiers (paths):')\n",
    "            for x in frontiers:\n",
    "                print('  -', x)\n",
    "            print('Visited:', visited)\n",
    "            print('\\n')\n",
    "            \n",
    "        # get the nodes in frontiers to be expanded\n",
    "        estimated_path_cost = []\n",
    "        for x in frontiers:\n",
    "            heuristic_value = heuristics_function[x[-1]]\n",
    "            path_cost = x[0]\n",
    "            estimated_path_cost.append(heuristic_value+path_cost)\n",
    "        idx_to_pop = estimated_path_cost.index(min(estimated_path_cost))\n",
    "        \n",
    "        path = frontiers.pop(idx_to_pop)\n",
    "        node = path[-1]  # Get the last node in this path\n",
    "        \n",
    "        if node == goal_state:\n",
    "            goal_path = path[1:]\n",
    "            goal_cost = path[0]\n",
    "            return goal_path, goal_cost\n",
    "        \n",
    "        if node in visited:  # check if we have expanded this node, if yes then skip this\n",
    "            continue\n",
    "            \n",
    "        actions = graph_to_search[node] # get the possible actions\n",
    "        for next_node, next_cost in actions:\n",
    "            new_path = path.copy()\n",
    "            new_path.append(next_node)\n",
    "            new_path[0] = new_path[0] + next_cost\n",
    "            \n",
    "            if next_node in visited or new_path in frontiers:\n",
    "                continue  # skip this node if it is already in the frontiers or the visited list.\n",
    "\n",
    "            frontiers.append(new_path)  # add to the frontiers\n",
    "        \n",
    "        # after exploring all actions, we add this node to the visited list\n",
    "        visited.append(node)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    initial_state = np.random.randint(0,21047)\n",
    "    goal_state = np.random.randint(0,21047)\n",
    "    print('The',i+1,'th combinations')\n",
    "    print(a_star_search(graph_search, initial_state, goal_state, heuristics_function=sld_to_des(goal_state), verbose=False))\n",
    "    print('----------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3\n",
    "![avator](./200_Question/question3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip uninstall requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip uninstall memory-profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'resource'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mresource\u001b[39;00m \n\u001b[0;32m      4\u001b[0m time_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'resource'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import resource \n",
    "\n",
    "time_start = time.perf_counter()\n",
    "\n",
    "for i in range(1000):\n",
    "    initial_state = np.random.randint(0,21047)\n",
    "    goal_state = np.random.randint(0,21047)\n",
    "    print('The',i+1,'th combinations')\n",
    "    print(a_star_search(graph_search, initial_state, goal_state, heuristics_function=sld_to_des(goal_state), verbose=False))\n",
    "    print('----------')\n",
    "\n",
    "time_elapsed = (time.perf_counter() - time_start)\n",
    "memMb=resource.getrusage(resource.RUSAGE_SELF).ru_maxrss/1024.0/1024.0\n",
    "print (time_elapsed,'secs',memMb,'MByte')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4\n",
    "![avator](./200_Question/question4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Depth Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Depth TREE\n",
    "def dfs_tree(graph_to_search, initial_state, goal_state, verbose=False):\n",
    "    frontiers = [[0, initial_state]]  # the frontier list only has the initial state, with a cost of 0.\n",
    "    visited = []\n",
    "    ver = 0 # to\n",
    "    while len(frontiers) > 0:   # use while loop to iteratively perform search\n",
    "        if verbose:  # print out detailed information in each iteration\n",
    "            print('Frontiers (paths):')\n",
    "            for x in frontiers:\n",
    "                print('  -', x)\n",
    "            print('Visited:', visited)\n",
    "            print('\\n')\n",
    "        path = frontiers.pop(-1)  # Get the last element in the list\n",
    "        node = path[-1]  # Get the last node in this path\n",
    "        \n",
    "        if node in visited:  # check if we have expanded this node, if yes then skip this\n",
    "            continue\n",
    "            \n",
    "        actions = graph_to_search[node] # get the possible actions\n",
    "        \n",
    "        if len(actions) == 0:#If next actions is empty, then pass this node,discard visited nodes\n",
    "            visited = copy.deepcopy(frontiers[-1])# Cover the old visited with the frontiers\n",
    "            del visited[0]# delate the cost information\n",
    "            del visited[-1]# delate the unvisited node\n",
    "            continue\n",
    "            \n",
    "        for next_node, next_cost in actions:\n",
    "            new_path = path.copy()\n",
    "            new_path.append(next_node)\n",
    "            new_path[0] = new_path[0] + next_cost\n",
    "            \n",
    "            if next_node in visited or new_path in frontiers:\n",
    "                continue  # skip this node if it is already in the frontiers or the visited list.\n",
    "            \n",
    "            # check if we reached the goal state or not\n",
    "            if next_node == goal_state:\n",
    "                goal_path = new_path[1:]\n",
    "                goal_cost = new_path[0]\n",
    "                return goal_path, goal_cost  # if yes, we can return this path and its cost\n",
    "            else:\n",
    "                frontiers.append(new_path)  # add to the frontiers\n",
    "        \n",
    "        # after exploring all actions, we add this node to the visited list\n",
    "        visited.append(node)\n",
    "        ver += 1\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    start_node = np.random.randint(0,len(df2))\n",
    "    end_node = np.random.randint(0,len(df2))\n",
    "    print('---',dfs_tree(graph_search,start_node,end_node,verbose = False),'\\n\\n\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Depth limited "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Depth_Limited_Search(graph_to_search, initial_state, goal_state, limited_deepth,verbose=False):\n",
    "\n",
    "    frontiers = [[0, initial_state]]  # the frontier list only has the initial state, with a cost of 0.\n",
    "    visited = []\n",
    "    \n",
    "    while len(frontiers) > 0:   # use while loop to iteratively perform search\n",
    "        if verbose:  # print out detailed information in each iteration\n",
    "            print('Frontiers (paths):')\n",
    "            for x in frontiers:\n",
    "                print('  -', x)\n",
    "            print('Visited:', visited)\n",
    "            print('\\n')\n",
    "        \n",
    "        path = frontiers.pop(-1)  # Get the last element in the list\n",
    "        node = path[-1]  # Get the last node in this path\n",
    "\n",
    "        if len(path)-1 == limited_deepth: \n",
    "            continue\n",
    "\n",
    "        if node in visited:  # check if we have expanded this node, if yes then skip this\n",
    "            continue\n",
    "            \n",
    "        actions = graph_to_search[node] # get the possible actions\n",
    "        for next_node, next_cost in actions:\n",
    "            new_path = path.copy()\n",
    "            new_path.append(next_node)\n",
    "            new_path[0] = new_path[0] + next_cost\n",
    "            \n",
    "            if next_node in visited or new_path in frontiers:\n",
    "                continue  # skip this node if it is already in the frontiers or the visited list.\n",
    "            \n",
    "            # check if we reached the goal state or not\n",
    "            if next_node == goal_state:\n",
    "                goal_path = new_path[1:]\n",
    "                goal_cost = new_path[0]\n",
    "                return goal_path, goal_cost  # if yes, we can return this path and its cost\n",
    "            else:\n",
    "                frontiers.append(new_path)  # add to the frontiers\n",
    "        \n",
    "        # after exploring all actions, we add this node to the visited list\n",
    "        visited.append(node)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Depth_Limited_Search(graph_search,0,1894,200,verbose = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative_Deepening_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterative_Deepening_dfs(graph_to_search, initial_state, goal_state, verbose=False):\n",
    "    limited_deepth = 0\n",
    "    now_deepth = -1\n",
    "\n",
    "    while now_deepth < limited_deepth:\n",
    "        frontiers = [[0, initial_state]]  # the frontier list only has the initial state, with a cost of 0.\n",
    "        visited = []\n",
    "        now_deepth += 1\n",
    "        \n",
    "        while len(frontiers) > 0:   # use while loop to iteratively perform search\n",
    "            if verbose:  # print out detailed information in each iteration\n",
    "                print('Frontiers (paths):')\n",
    "                for x in frontiers:\n",
    "                    print('  -', x)\n",
    "                print('Visited:', visited)\n",
    "                print('\\n')\n",
    "            \n",
    "            path = frontiers.pop(-1)  # Get the last element in the list\n",
    "            node = path[-1]  # Get the last node in this path\n",
    "\n",
    "            if len(path)-1 == limited_deepth: \n",
    "                continue\n",
    "\n",
    "            if node in visited:  # check if we have expanded this node, if yes then skip this\n",
    "                continue\n",
    "                \n",
    "            actions = graph_to_search[node] # get the possible actions\n",
    "            for next_node, next_cost in actions:\n",
    "                new_path = path.copy()\n",
    "                new_path.append(next_node)\n",
    "                new_path[0] = new_path[0] + next_cost\n",
    "                \n",
    "                if next_node in visited or new_path in frontiers:\n",
    "                    continue  # skip this node if it is already in the frontiers or the visited list.\n",
    "                \n",
    "                # check if we reached the goal state or not\n",
    "                if next_node == goal_state:\n",
    "                    goal_path = new_path[1:]\n",
    "                    goal_cost = new_path[0]\n",
    "                    return goal_path, goal_cost  # if yes, we can return this path and its cost\n",
    "                else:\n",
    "                    frontiers.append(new_path)  # add to the frontiers\n",
    "            \n",
    "            # after exploring all actions, we add this node to the visited list\n",
    "            visited.append(node)\n",
    "        \n",
    "        limited_deepth += 1\n",
    "        now_deepth = -1\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterative_Deepening_dfs(graph_search,0,1894,verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    start_node = np.random.randint(0,len(df2))\n",
    "    end_node = np.random.randint(0,len(df2))\n",
    "    print(iterative_Deepening_dfs(graph_search,start_node,end_node,verbose = False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterative_deepening_search_test(graph_to_search, initial_state, goal_state, verbose=False):\n",
    "    limit = 0\n",
    "    while True:\n",
    "        frontiers = [[0, initial_state]]\n",
    "        visited = []\n",
    "\n",
    "        while len(frontiers) > 0:\n",
    "            if verbose:\n",
    "                print(\"Frontiers (paths):\", frontiers)\n",
    "                print(\"Visited:\", visited, \"\\n\")\n",
    "\n",
    "            path = frontiers.pop(-1)\n",
    "            node = path[-1]\n",
    "\n",
    "            if len(path)-1 == limit:\n",
    "                continue\n",
    "\n",
    "            if node in visited:\n",
    "                continue\n",
    "\n",
    "            actions = graph_to_search[node]\n",
    "            for next_node, next_cost in actions:\n",
    "                new_path = path.copy()\n",
    "                new_path.append(next_node)\n",
    "                new_path[0] = new_path[0] + next_cost\n",
    "\n",
    "                if next_node in visited or new_path in frontiers:\n",
    "                    continue\n",
    "\n",
    "                if next_node == goal_state:\n",
    "                    goal_path = new_path[1:]\n",
    "                    goal_cost = new_path[0]\n",
    "                    return goal_path, goal_cost\n",
    "                else:\n",
    "                    frontiers.append(new_path)\n",
    "\n",
    "            visited.append(node)\n",
    "        limit += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(100):\n",
    "    start_node = np.random.randint(0,len(df2))\n",
    "    end_node = np.random.randint(0,len(df2))\n",
    "    print(iterative_deepening_search_test(graph_search,start_node,end_node,verbose = False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
